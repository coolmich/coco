{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import SVHN\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/jtao/Documents/coco/clock_algo/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "pwd = %pwd\n",
    "data = SVHN(\n",
    "    pwd, \n",
    "    download=True, \n",
    "    transform=lambda x: transforms.Normalize([0.5], [0.5])(transforms.ToTensor()(x.convert('L'))),\n",
    ")\n",
    "np.place(data.labels, data.labels == 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=data,\n",
    "                               batch_size=100,# 这里定义了batch_size\n",
    "                               shuffle=True,\n",
    "                               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 迭代开始，然后，队列和线程跟着也开始\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch 图像 和 标签\n",
    "images, labels = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb1c66ba90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[6].numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):#需要继承这个类\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #建立了两个卷积层，self.conv1, self.conv2，注意，这些层都是不包含激活函数的\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, 2) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #三个全连接层\n",
    "        self.fc1   = nn.Linear(16*10*10, 512) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(512, 128)\n",
    "        self.fc3   = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x): #注意，2D卷积层的输入data维数是 batchsize*channel*height*width\n",
    "        print(x.shape)\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        print(x.shape)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        print(x.shape)\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        print(x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(x.shape)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 6, 7, 7])\n",
      "torch.Size([100, 16, 1, 1])\n",
      "torch.Size([100, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [100 x 16], m2: [1600 x 512] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518371252923/work/torch/lib/TH/generic/THTensorMath.c:1434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-22926f4b2958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 这里就体现出来动态建图了，你还可以传入其他的参数来改变网络的结构\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jtao/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-43dcf08168b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jtao/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jtao/miniconda2/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jtao/miniconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [100 x 16], m2: [1600 x 512] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518371252923/work/torch/lib/TH/generic/THTensorMath.c:1434"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch 图像 和 标签\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "num_iteations = 10000\n",
    "\n",
    "# in your training loop:\n",
    "for i in range(num_iteations):\n",
    "    optimizer.zero_grad() # zero the gradient buffers，如果不归0的话，gradients会累加\n",
    "    \n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    output = net(Variable(images, requires_grad=True)) # 这里就体现出来动态建图了，你还可以传入其他的参数来改变网络的结构\\\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward() # 得到grad，i.e.给Variable.grad赋值\n",
    "    optimizer.step() # Does the update，i.e. Variable.data -= learning_rate*Variable.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 32, 32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
