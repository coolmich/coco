{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting image_util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile image_util.py\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import SVHN\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, save, load, from_numpy\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3) # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1   = nn.Linear(16*6*6, 128) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(128, 64)\n",
    "        self.fc3   = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "def pad_img(img):\n",
    "    desired_sz = 32\n",
    "    w, h = img.size\n",
    "    resize_ratio = desired_sz * 1.0 / max(w, h)\n",
    "    img = img.resize((int(w*resize_ratio), int(h*resize_ratio)))\n",
    "    \n",
    "    #pad image to make 32x32\n",
    "    w, h = img.size\n",
    "    delta_w = desired_sz - w\n",
    "    delta_h = desired_sz - h\n",
    "    padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "    return ImageOps.expand(\n",
    "        img, \n",
    "        padding\n",
    "    )\n",
    "\n",
    "def proc_fn(x):\n",
    "    return transforms.Normalize([0.5], [0.5])(transforms.ToTensor()(x.convert('L')))\n",
    "\n",
    "def preproc_pil_img(img):\n",
    "    # gray, norm, tensor\n",
    "    return proc_fn(pad_img(img))\n",
    "\n",
    "def file2tensor(file_path):\n",
    "    aa = preproc_pil_img(Image.open(file_path))\n",
    "    c, w, h = aa.size()\n",
    "    aa = aa.view((1, c, w, h))\n",
    "    return aa\n",
    "\n",
    "def cv2tensor(img):\n",
    "    if len(img.shape) > 2:\n",
    "        img = cv.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img)\n",
    "    aa = preproc_pil_img(pil_img)\n",
    "    c, w, h = aa.size()\n",
    "    aa = aa.view((1, c, w, h))\n",
    "    return aa\n",
    "    \n",
    "def predict_image(tensor, model):\n",
    "    output = model(Variable(tensor))\n",
    "    return np.exp(output.data.numpy())\n",
    "#     print(np.exp(output.data.numpy()))\n",
    "#     return np.argmax(output.data.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the folder is structured in the following way:\n",
    "#     -- data_folder\n",
    "#         -- label1\n",
    "#             -- image1\n",
    "#             -- image2\n",
    "#             -- ..\n",
    "#         -- label2\n",
    "#             -- image1\n",
    "#             -- ..\n",
    "#         -- ..\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data = []\n",
    "        for x in os.listdir(data_folder):\n",
    "            # list label folders\n",
    "            x_path = os.path.join(data_folder, x)\n",
    "            if os.path.isdir(x_path):\n",
    "                # list images in label folder\n",
    "                for y in os.listdir(x_path):\n",
    "                    if self._is_img(y):\n",
    "                        img = Image.open(os.path.join(x_path, y))\n",
    "                        self.data.append((transform(img), int(x)))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        #这里需要注意的是，第一步：read one data，是一个data\n",
    "        return self.data[index]\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _is_img(self, file_path):\n",
    "        return any([file_path.endswith(ext) for ext in ('.jpg', '.jpeg', '.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy from original data source to cropped labeled folder\n",
    "from digitStruct import *\n",
    "root = '/Users/jtao/Downloads/test'\n",
    "dsFileName = os.path.join(root, 'digitStruct.mat')\n",
    "data_agg = root + '_agg'\n",
    "if not os.path.exists(data_agg):\n",
    "    os.mkdir(data_agg)\n",
    "testCounter = 0\n",
    "for dsObj in yieldNextDigitStruct(dsFileName):\n",
    "    break\n",
    "    testCounter += 1\n",
    "    if not testCounter % 1000:\n",
    "        print(testCounter)\n",
    "#     print(dsObj.name)\n",
    "    img_file_path = os.path.join(root, dsObj.name)\n",
    "    img = Image.open(img_file_path)\n",
    "    for bbox in dsObj.bboxList:\n",
    "#         print(\"    {}:{},{},{},{}\".format(\n",
    "#             bbox.label, bbox.left, bbox.top, bbox.width, bbox.height))\n",
    "        label_dir = os.path.join(data_agg, str(bbox.label))\n",
    "        if not os.path.exists(label_dir):\n",
    "            os.mkdir(label_dir)\n",
    "        cropped = img.crop((bbox.left, bbox.top, bbox.left+bbox.width, bbox.top+bbox.height))\n",
    "        padded = pad_img(cropped)\n",
    "        padded.save(os.path.join(label_dir, str(dsObj.name) + '_' + str(bbox.left) + '_' + str(bbox.top) + '.png'))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = %pwd\n",
    "proc_fn = lambda x: transforms.Normalize([0.5], [0.5])(transforms.ToTensor()(x.convert('L')))\n",
    "# data = SVHN(\n",
    "#     pwd, \n",
    "#     download=True, \n",
    "#     transform=proc_fn,\n",
    "# )\n",
    "data = LabeledDataset('/Users/jtao/Downloads/train_agg/', transform=proc_fn)\n",
    "# np.place(data.labels, data.labels == 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = %pwd\n",
    "# test = SVHN(\n",
    "#     pwd, \n",
    "#     split='test',\n",
    "#     download=True, \n",
    "#     transform=proc_fn,\n",
    "# )\n",
    "test = LabeledDataset('/Users/jtao/Downloads/test_agg/', transform=proc_fn)\n",
    "# np.place(test.labels, test.labels == 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=data,\n",
    "                               batch_size=100,# 这里定义了batch_size\n",
    "                               shuffle=True,\n",
    "                               num_workers=2)\n",
    "test_loader = DataLoader(dataset=test,\n",
    "                               batch_size=100,# 这里定义了batch_size\n",
    "                               shuffle=True,\n",
    "                               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 迭代开始，然后，队列和线程跟着也开始\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch 图像 和 标签\n",
    "images, labels = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 3\n",
       " 6\n",
       " 0\n",
       " 8\n",
       " 4\n",
       " 7\n",
       " 4\n",
       " 0\n",
       " 2\n",
       " 5\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 1\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 1\n",
       " 3\n",
       " 7\n",
       " 6\n",
       " 1\n",
       " 6\n",
       " 2\n",
       " 8\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 5\n",
       " 8\n",
       " 4\n",
       " 7\n",
       " 3\n",
       " 9\n",
       " 5\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 7\n",
       " 3\n",
       " 0\n",
       " 3\n",
       " 4\n",
       " 6\n",
       " 0\n",
       " 5\n",
       " 2\n",
       " 8\n",
       " 4\n",
       " 9\n",
       " 1\n",
       " 3\n",
       " 7\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 9\n",
       " 9\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 5\n",
       " 4\n",
       " 4\n",
       " 5\n",
       " 3\n",
       " 8\n",
       " 9\n",
       " 1\n",
       " 4\n",
       " 4\n",
       " 9\n",
       " 7\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 5\n",
       " 1\n",
       " 7\n",
       " 4\n",
       " 5\n",
       " 1\n",
       " 5\n",
       " 1\n",
       " 4\n",
       " 0\n",
       " 7\n",
       " 7\n",
       " 2\n",
       " 3\n",
       "[torch.LongTensor of size 100]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121e91a10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[9].numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0: loss Variable containing:\n",
      " 2.3031\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.147567567568\n",
      "Epoch 0 batch 300: loss Variable containing:\n",
      " 2.2459\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.193243243243\n",
      "Epoch 0 batch 600: loss Variable containing:\n",
      " 2.2456\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.200675675676\n",
      "Test acc: 0.231481481481\n",
      "Epoch 1 batch 0: loss Variable containing:\n",
      " 2.2056\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.206486486486\n",
      "Epoch 1 batch 300: loss Variable containing:\n",
      " 2.0072\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.237432432432\n",
      "Epoch 1 batch 600: loss Variable containing:\n",
      " 2.1785\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.244324324324\n",
      "Test acc: 0.24\n",
      "Epoch 2 batch 0: loss Variable containing:\n",
      " 2.1580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.237837837838\n",
      "Epoch 2 batch 300: loss Variable containing:\n",
      " 2.0630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.246756756757\n",
      "Epoch 2 batch 600: loss Variable containing:\n",
      " 2.1381\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.243108108108\n",
      "Test acc: 0.235925925926\n",
      "Epoch 3 batch 0: loss Variable containing:\n",
      " 2.1677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.244594594595\n",
      "Epoch 3 batch 300: loss Variable containing:\n",
      " 2.1671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.246081081081\n",
      "Epoch 3 batch 600: loss Variable containing:\n",
      " 2.0793\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.241891891892\n",
      "Test acc: 0.253703703704\n",
      "Epoch 4 batch 0: loss Variable containing:\n",
      " 2.1328\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.252297297297\n",
      "Epoch 4 batch 300: loss Variable containing:\n",
      " 2.1250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.244324324324\n",
      "Epoch 4 batch 600: loss Variable containing:\n",
      " 2.1534\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.243648648649\n",
      "Test acc: 0.239259259259\n",
      "Epoch 5 batch 0: loss Variable containing:\n",
      " 2.0896\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.250405405405\n",
      "Epoch 5 batch 300: loss Variable containing:\n",
      " 2.1335\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.233108108108\n",
      "Epoch 5 batch 600: loss Variable containing:\n",
      " 2.2128\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.250540540541\n",
      "Test acc: 0.258888888889\n",
      "Epoch 6 batch 0: loss Variable containing:\n",
      " 2.0882\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.243513513514\n",
      "Epoch 6 batch 300: loss Variable containing:\n",
      " 2.1097\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.257432432432\n",
      "Epoch 6 batch 600: loss Variable containing:\n",
      " 2.1893\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.249864864865\n",
      "Test acc: 0.261111111111\n",
      "Epoch 7 batch 0: loss Variable containing:\n",
      " 2.0546\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.244594594595\n",
      "Epoch 7 batch 300: loss Variable containing:\n",
      " 2.1636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.255945945946\n",
      "Epoch 7 batch 600: loss Variable containing:\n",
      " 2.0310\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.254459459459\n",
      "Test acc: 0.242962962963\n",
      "Epoch 8 batch 0: loss Variable containing:\n",
      " 2.1870\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.256081081081\n",
      "Epoch 8 batch 300: loss Variable containing:\n",
      " 2.0708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.257432432432\n",
      "Epoch 8 batch 600: loss Variable containing:\n",
      " 2.1252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.258243243243\n",
      "Test acc: 0.262962962963\n",
      "Epoch 9 batch 0: loss Variable containing:\n",
      " 2.0251\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.263108108108\n",
      "Epoch 9 batch 300: loss Variable containing:\n",
      " 2.0425\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.271891891892\n",
      "Epoch 9 batch 600: loss Variable containing:\n",
      " 2.0201\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.268108108108\n",
      "Test acc: 0.284444444444\n",
      "Epoch 10 batch 0: loss Variable containing:\n",
      " 2.0467\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.295810810811\n",
      "Epoch 10 batch 300: loss Variable containing:\n",
      " 2.1377\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.301756756757\n",
      "Epoch 10 batch 600: loss Variable containing:\n",
      " 1.9400\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.317297297297\n",
      "Test acc: 0.371851851852\n",
      "Epoch 11 batch 0: loss Variable containing:\n",
      " 1.8373\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.385675675676\n",
      "Epoch 11 batch 300: loss Variable containing:\n",
      " 1.8564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.395810810811\n",
      "Epoch 11 batch 600: loss Variable containing:\n",
      " 1.5907\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.445405405405\n",
      "Test acc: 0.427407407407\n",
      "Epoch 12 batch 0: loss Variable containing:\n",
      " 1.5727\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.468243243243\n",
      "Epoch 12 batch 300: loss Variable containing:\n",
      " 1.5769\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.506621621622\n",
      "Epoch 12 batch 600: loss Variable containing:\n",
      " 1.4326\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.483108108108\n",
      "Test acc: 0.528888888889\n",
      "Epoch 13 batch 0: loss Variable containing:\n",
      " 1.3362\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.540405405405\n",
      "Epoch 13 batch 300: loss Variable containing:\n",
      " 1.4075\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.614864864865\n",
      "Epoch 13 batch 600: loss Variable containing:\n",
      " 1.0172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.622567567568\n",
      "Test acc: 0.564444444444\n",
      "Epoch 14 batch 0: loss Variable containing:\n",
      " 1.2838\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.561621621622\n",
      "Epoch 14 batch 300: loss Variable containing:\n",
      " 1.1829\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.661621621622\n",
      "Epoch 14 batch 600: loss Variable containing:\n",
      " 0.9677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.696486486486\n",
      "Test acc: 0.667037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtao/miniconda2/lib/python2.7/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 batch 0: loss Variable containing:\n",
      " 1.1463\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.700945945946\n",
      "Epoch 15 batch 300: loss Variable containing:\n",
      " 0.8621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.72472972973\n",
      "Epoch 15 batch 600: loss Variable containing:\n",
      " 0.7495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.746216216216\n",
      "Test acc: 0.703333333333\n",
      "Epoch 16 batch 0: loss Variable containing:\n",
      " 0.8727\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.756351351351\n",
      "Epoch 16 batch 300: loss Variable containing:\n",
      " 0.8407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.758243243243\n",
      "Epoch 16 batch 600: loss Variable containing:\n",
      " 0.8409\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.746081081081\n",
      "Test acc: 0.744444444444\n",
      "Epoch 17 batch 0: loss Variable containing:\n",
      " 0.7105\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.777162162162\n",
      "Epoch 17 batch 300: loss Variable containing:\n",
      " 0.7482\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.780945945946\n",
      "Epoch 17 batch 600: loss Variable containing:\n",
      " 0.7148\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.779189189189\n",
      "Test acc: 0.754074074074\n",
      "Epoch 18 batch 0: loss Variable containing:\n",
      " 0.5855\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.798243243243\n",
      "Epoch 18 batch 300: loss Variable containing:\n",
      " 0.6599\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.782837837838\n",
      "Epoch 18 batch 600: loss Variable containing:\n",
      " 0.7791\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.802297297297\n",
      "Test acc: 0.801111111111\n",
      "Epoch 19 batch 0: loss Variable containing:\n",
      " 0.6953\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.805945945946\n",
      "Epoch 19 batch 300: loss Variable containing:\n",
      " 0.6565\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.816891891892\n",
      "Epoch 19 batch 600: loss Variable containing:\n",
      " 0.7684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.822027027027\n",
      "Test acc: 0.784074074074\n",
      "Epoch 20 batch 0: loss Variable containing:\n",
      " 0.7603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.824594594595\n",
      "Epoch 20 batch 300: loss Variable containing:\n",
      " 0.6087\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.827567567568\n",
      "Epoch 20 batch 600: loss Variable containing:\n",
      " 0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.81527027027\n",
      "Test acc: 0.745555555556\n",
      "Epoch 21 batch 0: loss Variable containing:\n",
      " 0.5985\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.829864864865\n",
      "Epoch 21 batch 300: loss Variable containing:\n",
      " 0.6236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.831756756757\n",
      "Epoch 21 batch 600: loss Variable containing:\n",
      " 0.4434\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.829189189189\n",
      "Test acc: 0.790740740741\n",
      "Epoch 22 batch 0: loss Variable containing:\n",
      " 0.4191\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.832297297297\n",
      "Epoch 22 batch 300: loss Variable containing:\n",
      " 0.3346\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.834324324324\n",
      "Epoch 22 batch 600: loss Variable containing:\n",
      " 0.7132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.839324324324\n",
      "Test acc: 0.811111111111\n",
      "Epoch 23 batch 0: loss Variable containing:\n",
      " 0.5302\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.826081081081\n",
      "Epoch 23 batch 300: loss Variable containing:\n",
      " 0.6045\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.826351351351\n",
      "Epoch 23 batch 600: loss Variable containing:\n",
      " 0.4408\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.838648648649\n",
      "Test acc: 0.82\n",
      "Epoch 24 batch 0: loss Variable containing:\n",
      " 0.2864\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.841756756757\n",
      "Epoch 24 batch 300: loss Variable containing:\n",
      " 0.5470\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.841351351351\n",
      "Epoch 24 batch 600: loss Variable containing:\n",
      " 0.4280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.845810810811\n",
      "Test acc: 0.80962962963\n",
      "Epoch 25 batch 0: loss Variable containing:\n",
      " 0.4891\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.845135135135\n",
      "Epoch 25 batch 300: loss Variable containing:\n",
      " 0.5747\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.855945945946\n",
      "Epoch 25 batch 600: loss Variable containing:\n",
      " 0.5334\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.851486486486\n",
      "Test acc: 0.821851851852\n",
      "Epoch 26 batch 0: loss Variable containing:\n",
      " 0.5128\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.852567567568\n",
      "Epoch 26 batch 300: loss Variable containing:\n",
      " 0.4892\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.857297297297\n",
      "Epoch 26 batch 600: loss Variable containing:\n",
      " 0.4345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.851756756757\n",
      "Test acc: 0.805185185185\n",
      "Epoch 27 batch 0: loss Variable containing:\n",
      " 0.4851\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.854459459459\n",
      "Epoch 27 batch 300: loss Variable containing:\n",
      " 0.6516\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.859189189189\n",
      "Epoch 27 batch 600: loss Variable containing:\n",
      " 0.4043\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.856216216216\n",
      "Test acc: 0.823333333333\n",
      "Epoch 28 batch 0: loss Variable containing:\n",
      " 0.5704\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.862027027027\n",
      "Epoch 28 batch 300: loss Variable containing:\n",
      " 0.5249\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.849324324324\n",
      "Epoch 28 batch 600: loss Variable containing:\n",
      " 0.4236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.859054054054\n",
      "Test acc: 0.831851851852\n",
      "Epoch 29 batch 0: loss Variable containing:\n",
      " 0.5888\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.854459459459\n",
      "Epoch 29 batch 300: loss Variable containing:\n",
      " 0.3796\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.864054054054\n",
      "Epoch 29 batch 600: loss Variable containing:\n",
      " 0.4385\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.864324324324\n",
      "Test acc: 0.825555555556\n",
      "Epoch 30 batch 0: loss Variable containing:\n",
      " 0.2550\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.862027027027\n",
      "Epoch 30 batch 300: loss Variable containing:\n",
      " 0.3791\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.859864864865\n",
      "Epoch 30 batch 600: loss Variable containing:\n",
      " 0.3825\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.871081081081\n",
      "Test acc: 0.841851851852\n",
      "Epoch 31 batch 0: loss Variable containing:\n",
      " 0.6424\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.87027027027\n",
      "Epoch 31 batch 300: loss Variable containing:\n",
      " 0.4825\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.863378378378\n",
      "Epoch 31 batch 600: loss Variable containing:\n",
      " 0.4510\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.867297297297\n",
      "Test acc: 0.838888888889\n",
      "Epoch 32 batch 0: loss Variable containing:\n",
      " 0.3529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.864054054054\n",
      "Epoch 32 batch 300: loss Variable containing:\n",
      " 0.4567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.86527027027\n",
      "Epoch 32 batch 600: loss Variable containing:\n",
      " 0.2097\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.87472972973\n",
      "Test acc: 0.832222222222\n",
      "Epoch 33 batch 0: loss Variable containing:\n",
      " 0.3979\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.865540540541\n",
      "Epoch 33 batch 300: loss Variable containing:\n",
      " 0.4040\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.872972972973\n",
      "Epoch 33 batch 600: loss Variable containing:\n",
      " 0.5127\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.870135135135\n",
      "Test acc: 0.834074074074\n",
      "Epoch 34 batch 0: loss Variable containing:\n",
      " 0.3745\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.878243243243\n",
      "Epoch 34 batch 300: loss Variable containing:\n",
      " 0.5007\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.870675675676\n",
      "Epoch 34 batch 600: loss Variable containing:\n",
      " 0.5413\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.875540540541\n",
      "Test acc: 0.836296296296\n",
      "Epoch 35 batch 0: loss Variable containing:\n",
      " 0.4551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.87\n",
      "Epoch 35 batch 300: loss Variable containing:\n",
      " 0.6330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.880810810811\n",
      "Epoch 35 batch 600: loss Variable containing:\n",
      " 0.4207\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.878783783784\n",
      "Test acc: 0.814074074074\n",
      "Epoch 36 batch 0: loss Variable containing:\n",
      " 0.4648\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.873918918919\n",
      "Epoch 36 batch 300: loss Variable containing:\n",
      " 0.3208\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.881756756757\n",
      "Epoch 36 batch 600: loss Variable containing:\n",
      " 0.3166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.877972972973\n",
      "Test acc: 0.826296296296\n",
      "Epoch 37 batch 0: loss Variable containing:\n",
      " 0.3920\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.87972972973\n",
      "Epoch 37 batch 300: loss Variable containing:\n",
      " 0.2755\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.86527027027\n",
      "Epoch 37 batch 600: loss Variable containing:\n",
      " 0.4431\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.872837837838\n",
      "Test acc: 0.824444444444\n",
      "Epoch 38 batch 0: loss Variable containing:\n",
      " 0.2488\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.880540540541\n",
      "Epoch 38 batch 300: loss Variable containing:\n",
      " 0.3258\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.886081081081\n",
      "Epoch 38 batch 600: loss Variable containing:\n",
      " 0.4447\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.884864864865\n",
      "Test acc: 0.835185185185\n",
      "Epoch 39 batch 0: loss Variable containing:\n",
      " 0.3717\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.878378378378\n",
      "Epoch 39 batch 300: loss Variable containing:\n",
      " 0.3300\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.887567567568\n",
      "Epoch 39 batch 600: loss Variable containing:\n",
      " 0.4117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.873918918919\n",
      "Test acc: 0.850740740741\n",
      "Epoch 40 batch 0: loss Variable containing:\n",
      " 0.4600\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.885540540541\n",
      "Epoch 40 batch 300: loss Variable containing:\n",
      " 0.3394\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.88472972973\n",
      "Epoch 40 batch 600: loss Variable containing:\n",
      " 0.3646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.890135135135\n",
      "Test acc: 0.85037037037\n",
      "Epoch 41 batch 0: loss Variable containing:\n",
      " 0.3997\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.890405405405\n",
      "Epoch 41 batch 300: loss Variable containing:\n",
      " 0.3595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.89027027027\n",
      "Epoch 41 batch 600: loss Variable containing:\n",
      " 0.2175\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.890945945946\n",
      "Test acc: 0.848148148148\n",
      "Epoch 42 batch 0: loss Variable containing:\n",
      " 0.3850\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.885\n",
      "Epoch 42 batch 300: loss Variable containing:\n",
      " 0.2583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.886081081081\n",
      "Epoch 42 batch 600: loss Variable containing:\n",
      " 0.2615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Training acc: 0.892162162162\n",
      "Test acc: 0.847407407407\n",
      "Test acc going down consecutively 3 times, stop training\n"
     ]
    }
   ],
   "source": [
    "def error_rate(loader, model, sample_rate=0.1):\n",
    "    err = []\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx > len(loader) * sample_rate: break\n",
    "        output = net(Variable(images))\n",
    "        output = np.argmax(output.data.numpy(), axis=1)\n",
    "        err.append(np.sum(output != labels.squeeze().numpy()) * 1.0 / len(output))\n",
    "    return np.mean(err)\n",
    "\n",
    "        \n",
    "net = Net()\n",
    "# data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch 图像 和 标签\n",
    "# images, labels = next(data_iter)\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "num_epoch = 1000\n",
    "\n",
    "test_acc_arr = []\n",
    "\n",
    "# in your training loop:\n",
    "for i in range(num_epoch):\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # zero the gradient buffers，如果不归0的话，gradients会累加\n",
    "\n",
    "        output = net(Variable(images)) # 这里就体现出来动态建图了，你还可以传入其他的参数来改变网络的结构\\\n",
    "        target = Variable(labels).squeeze().long()\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() # 得到grad，i.e.给Variable.grad赋值\n",
    "        optimizer.step() # Does the update，i.e. Variable.data -= learning_rate*Variable.grad\n",
    "\n",
    "        if not batch_idx % 300:\n",
    "            print('Epoch {} batch {}: loss {}'.format(i, batch_idx, loss))\n",
    "            print('Training acc: {}'.format(1.0 - error_rate(train_loader, net)))\n",
    "    test_acc = 1.0 - error_rate(test_loader, net)\n",
    "    print('Test acc: {}'.format(test_acc))\n",
    "    test_acc_arr.append(test_acc)\n",
    "    if test_acc > 0.6:\n",
    "        save(net, 'cropped_vanilla_model_epoch_{}.pkl'.format(i))\n",
    "        if len(test_acc_arr) > 3 and test_acc_arr[-1] < test_acc_arr[-2] < test_acc_arr[-3] < test_acc_arr[-4]:\n",
    "            print('Test acc going down consecutively 3 times, stop training')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_4'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load('vanilla_model_epoch_60.pkl')\n",
    "model = load('cropped_vanilla_model_epoch_39.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.48642704e-02   1.57538409e-04   5.22932062e-08   1.33300069e-04\n",
      "    6.29064045e-09   5.89202112e-03   9.27175045e-01   5.04703030e-06\n",
      "    1.74215983e-03   3.05864123e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = file2tensor('clocks/num11.png')\n",
    "predict_image(tensor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  2.71828183])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18172115, 0.81269883, 0.30181448, 0.8013887 ],\n",
       "       [0.51834583, 0.0633119 , 0.1472658 , 0.07491638],\n",
       "       [0.46951932, 0.97698501, 0.54223489, 0.23656321]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.random.rand(3, 4)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(aa, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x:x+1, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = Image.open('/Users/jtao/Downloads/train/1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "croped = img.crop((246,77,246+81,77+219))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAADXklEQVR4nKXVSW4dNxAG4CoWhyZ7\neNKTPCTIIkBW2foG2WSb4+YAuYFjI6sAli0biaNnv0E9cKrKDdQGurds8sPPYpEIT36//foL2wOX\n64A8+SmMXmg8P4a3f38ebPvjD/X3P/58egX19LB4brBr3MWA0gsKXZas394dswwHe690eHo6AOiV\nYX2WuRcJM9Llwb4/SBnPySkz+2vzgm1cBVYSIASrFWhZ6DHlOtW70GhbAnezqJmItibwqQoRVdNi\nlRt6dfvzY84P785NtpqC5v1WgGkQZEvHC0kTquagBELxgkUaQ5i3AklPoHRi7mLIoIF11JGlugR9\nUGLLKrBSg37eM3Oou6hZ3GLpS3oMntXRc/EemLcCuZsaoQ6kzXsQm5abL+fzMpub7Pf2cwfdVqBC\nEl0j76KKRLbpY87OaXcKs7VqsWkrQGyM9GBPhizBQaBd5sQmOpuVudJlvchrW1Sg5orKaAWz7jxk\nfcRacSBXuAVZ74MVwCsAXWeaE0kTw0nhaCjaDKq2wgX6rUDRMyIqmazKBcaxKjHmUlA7lTV7rlsB\nxJYtEw5zjVZ2VyMPALfcp3YWg2KWrUBFJRAFmlZa1Tw8oDozgp/20Bu4TyCrwNpdVF0uXnGNptRi\n7ZlFJUbjkDW/RDNvTZDt7MzDV52dJMbm8Kh2PHicnzU9oyW+3QrUNMwy9HZKeWDK8QOdYRElczsn\ng+DOWwHn81AaYDRNvIrd6NKOjcdm0LvbQhHs5gTZjuGkTFswReAP/pSdgf0Z6XKm3vFKCb8B8J+A\n0bLWMjBzu3Qx8UC+8C7gEdQ6sPJHm76rwrFqJQuC2Vet9AkcEJ2K9Ejrx3QlQTTRCrXISvQ0EtiE\nVfVGg5iqQMvmBE7MYiTiA5Sb43iqoqozrFVGi0ilbO4Dq33Ro63PWf373/txMajUcbxYgcUXszTr\nT+ZKglIna+XT68PHEx1UCFgqdkQx36t/+q/PldkKoFmQ+0RTVBfUdw7CEemvw0wxdcPuzet2KwDY\nSqnt9/c/7VpJPoO8ZA0Miq6f3YaPV4d3d9sArkQMQd/CgCBYkm/qWPQzQFfYvuw9wJtNgDIlutxb\nMulmScC7Uzu9OOmzMlxSNmZzDSZJO25H6Wq46HDV1C4PMZBmScb5b2gD+B+uAOAGWUb+xAAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x114923ED0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_img(croped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jtao/Downloads/train_agg/9 has 4659 files\n",
      "/Users/jtao/Downloads/train_agg/0 has 4948 files\n",
      "/Users/jtao/Downloads/train_agg/7 has 5595 files\n",
      "/Users/jtao/Downloads/train_agg/6 has 5727 files\n",
      "/Users/jtao/Downloads/train_agg/1 has 13861 files\n",
      "/Users/jtao/Downloads/train_agg/8 has 5045 files\n",
      "/Users/jtao/Downloads/train_agg/4 has 7458 files\n",
      "/Users/jtao/Downloads/train_agg/3 has 8497 files\n",
      "/Users/jtao/Downloads/train_agg/2 has 10585 files\n",
      "/Users/jtao/Downloads/train_agg/5 has 6882 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root = '/Users/jtao/Downloads/train_agg'\n",
    "for dire in os.listdir(root):\n",
    "    dire = os.path.join(root, dire)\n",
    "    if os.path.isdir(dire):\n",
    "        print('{} has {} files'.format(dire, len(os.listdir(dire))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
